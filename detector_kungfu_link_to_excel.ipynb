{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "detector_kungfu.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlenaAntipina/KungfuGameDetector/blob/main/detector_kungfu_link_to_excel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_A8QstGulaY",
        "outputId": "c038b831-7578-404c-d172-40212380bfcc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ultralytics/yolov5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTZMe3U3vOmv",
        "outputId": "c1d24117-1efe-4d56-c7bd-95e0d3cb2a3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 12313, done.\u001b[K\n",
            "remote: Counting objects: 100% (32/32), done.\u001b[K\n",
            "remote: Compressing objects: 100% (30/30), done.\u001b[K\n",
            "remote: Total 12313 (delta 14), reused 6 (delta 2), pack-reused 12281\u001b[K\n",
            "Receiving objects: 100% (12313/12313), 12.08 MiB | 29.51 MiB/s, done.\n",
            "Resolving deltas: 100% (8489/8489), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r yolov5/requirements.txt"
      ],
      "metadata": {
        "id": "grxoYX7-vQ0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('new_train_yaml', 'w+') as file:\n",
        "    file.write(\n",
        "        \"\"\"\n",
        "        # parameters\n",
        "        nc: 3  # number of classes\n",
        "        depth_multiple: 0.33  # model depth multiple\n",
        "        width_multiple: 0.50  # layer channel multiple\n",
        "\n",
        "        # anchors\n",
        "        anchors:\n",
        "          - [10,13, 16,30, 33,23]  # P3/8\n",
        "          - [30,61, 62,45, 59,119]  # P4/16\n",
        "          - [116,90, 156,198, 373,326]  # P5/32\n",
        "\n",
        "        # YOLOv5 backbone\n",
        "        backbone:\n",
        "          # [from, number, module, args]\n",
        "          [[-1, 1, Focus, [64, 3]],  # 0-P1/2\n",
        "           [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4\n",
        "           [-1, 3, BottleneckCSP, [128]],\n",
        "           [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8\n",
        "           [-1, 9, BottleneckCSP, [256]],\n",
        "           [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16\n",
        "           [-1, 9, BottleneckCSP, [512]],\n",
        "           [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32\n",
        "           [-1, 1, SPP, [1024, [5, 9, 13]]],\n",
        "           [-1, 3, BottleneckCSP, [1024, False]],  # 9\n",
        "          ]\n",
        "\n",
        "        # YOLOv5 head\n",
        "        head:\n",
        "          [[-1, 1, Conv, [512, 1, 1]],\n",
        "           [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
        "           [[-1, 6], 1, Concat, [1]],  # cat backbone P4\n",
        "           [-1, 3, BottleneckCSP, [512, False]],  # 13\n",
        "\n",
        "           [-1, 1, Conv, [256, 1, 1]],\n",
        "           [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
        "           [[-1, 4], 1, Concat, [1]],  # cat backbone P3\n",
        "           [-1, 3, BottleneckCSP, [256, False]],  # 17 (P3/8-small)\n",
        "\n",
        "           [-1, 1, Conv, [256, 3, 2]],\n",
        "           [[-1, 14], 1, Concat, [1]],  # cat head P4\n",
        "           [-1, 3, BottleneckCSP, [512, False]],  # 20 (P4/16-medium)\n",
        "\n",
        "           [-1, 1, Conv, [512, 3, 2]],\n",
        "           [[-1, 10], 1, Concat, [1]],  # cat head P5\n",
        "           [-1, 3, BottleneckCSP, [1024, False]],  # 23 (P5/32-large)\n",
        "\n",
        "           [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)\n",
        "          ]\n",
        "        \"\"\"\n",
        "    )"
      ],
      "metadata": {
        "id": "hkUIrDrtvQ6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('new_data_yaml', 'w+') as file:\n",
        "    file.write(\n",
        "        \"\"\"\n",
        "        train: /content/gdrive/MyDrive/Detector/dataset_game/images/train\n",
        "        val: /content/gdrive/MyDrive/Detector/dataset_game/images/valid\n",
        "\n",
        "        nc: 3\n",
        "        names: ['NPC', 'Hero', 'bullet']\n",
        "        \"\"\"\n",
        "    )"
      ],
      "metadata": {
        "id": "XSn-pQ7UvRAK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/yolov5/train.py --img 416 --batch 16 --epochs 500 --data /content/new_data_yaml --cfg /content/new_train_yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAdbxNtcvRGQ",
        "outputId": "f3ad5402-4e18-40e5-f332-632aca87ddf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   309/499     1.89G  0.007246  0.003009 0.0003529        15       416: 100% 100/100 [00:21<00:00,  4.56it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 10/10 [00:02<00:00,  4.94it/s]\n",
            "                 all        301        410      0.999      0.996      0.995      0.955\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "   310/499     1.89G   0.00782  0.003141 0.0004635        18       416: 100% 100/100 [00:21<00:00,  4.57it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 10/10 [00:02<00:00,  4.84it/s]\n",
            "                 all        301        410      0.999      0.996      0.995      0.955\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "   311/499     1.89G  0.007168  0.002957  0.000371        13       416: 100% 100/100 [00:22<00:00,  4.52it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 10/10 [00:02<00:00,  4.90it/s]\n",
            "                 all        301        410      0.999      0.996      0.995      0.959\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "  0% 0/100 [00:00<?, ?it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/yolov5/train.py\", line 670, in <module>\n",
            "    main(opt)\n",
            "  File \"/content/yolov5/train.py\", line 565, in main\n",
            "    train(opt.hyp, opt, device, callbacks)\n",
            "  File \"/content/yolov5/train.py\", line 360, in train\n",
            "    scaler.scale(loss).backward()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\", line 363, in backward\n",
            "    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\", line 175, in backward\n",
            "    allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !python /content/yolov5/train.py --img 416 --batch 16 --epochs 200 --data /content/new_data_yaml --cfg /content/new_train_yaml --weights /content/yolov5/runs/train/exp/weights/last.pt"
      ],
      "metadata": {
        "id": "oCrugeCxEwj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/yolov5/detect.py --source /content/gdrive/MyDrive/Detector/image3.png --weights '/content/yolov5/runs/train/exp/weights/best.pt' --img 416 --conf 0.5 --save-txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PqctHTVq6Dpz",
        "outputId": "c8a85df8-5562-454d-bb03-f8e4bbcf7396"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/yolov5/runs/train/exp/weights/best.pt'], source=/content/gdrive/MyDrive/Detector/image3.png, data=yolov5/data/coco128.yaml, imgsz=[416, 416], conf_thres=0.5, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=True, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov5/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False\n",
            "YOLOv5 🚀 v6.1-265-g8ebf569 Python-3.7.13 torch-1.11.0+cu113 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "Fusing layers... \n",
            "new_train_yaml summary: 232 layers, 7251912 parameters, 0 gradients\n",
            "image 1/1 /content/gdrive/MyDrive/Detector/image3.png: 224x416 1 bullet, Done. (0.017s)\n",
            "Speed: 0.4ms pre-process, 16.9ms inference, 1.3ms NMS per image at shape (1, 3, 416, 416)\n",
            "Results saved to \u001b[1myolov5/runs/detect/exp4\u001b[0m\n",
            "1 labels saved to yolov5/runs/detect/exp4/labels\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import pandas"
      ],
      "metadata": {
        "id": "UJq7vGp18pPy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.hub.load('ultralytics/yolov5', 'custom', path='/content/yolov5/runs/train/exp/weights/best.pt', force_reload=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mC5TmT381so",
        "outputId": "c8891142-44c2-4cf6-affe-c6672bfe7c96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/ultralytics/yolov5/archive/master.zip\" to /root/.cache/torch/hub/master.zip\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m PyYAML>=5.3.1 not found and is required by YOLOv5, attempting auto-update...\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.7/dist-packages (6.0)\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m 1 package updated per /root/.cache/torch/hub/ultralytics_yolov5_master/requirements.txt\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m ⚠️ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "YOLOv5 🚀 2022-6-27 Python-3.7.13 torch-1.11.0+cu113 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "Fusing layers... \n",
            "new_train_yaml summary: 232 layers, 7251912 parameters, 0 gradients\n",
            "Adding AutoShape... \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "from numpy import asarray\n",
        "\n",
        "# load the image and convert into numpy array\n",
        "img = Image.open('Sample.png')\n",
        "\n",
        "# asarray() class is used to convert PIL images into NumPy arrays\n",
        "numpydata = asarray(img)\n",
        "\n",
        "# <class 'numpy.ndarray'>\n",
        "print(type(numpydata))\n",
        "\n",
        "#  shape\n",
        "print(numpydata.shape)"
      ],
      "metadata": {
        "id": "xq-6DRitAHVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = '/content/gdrive/MyDrive/Detector/image2.png'\n",
        "results = model(image)\n",
        "results.pandas().xyxy[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "8P_g_Y_N9Z2H",
        "outputId": "b1d6ac5d-4e99-4db0-98c3-c40f31bf530b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        xmin       ymin       xmax       ymax  confidence  class    name\n",
              "0  56.712124  31.855856  68.648643  62.362316    0.960145      1  bullet\n",
              "1  49.642105  25.497768  56.354744  58.142731    0.954689      0    Hero"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-efe50d4c-ebfe-44c0-9124-c0840523dac2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>xmin</th>\n",
              "      <th>ymin</th>\n",
              "      <th>xmax</th>\n",
              "      <th>ymax</th>\n",
              "      <th>confidence</th>\n",
              "      <th>class</th>\n",
              "      <th>name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>56.712124</td>\n",
              "      <td>31.855856</td>\n",
              "      <td>68.648643</td>\n",
              "      <td>62.362316</td>\n",
              "      <td>0.960145</td>\n",
              "      <td>1</td>\n",
              "      <td>bullet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>49.642105</td>\n",
              "      <td>25.497768</td>\n",
              "      <td>56.354744</td>\n",
              "      <td>58.142731</td>\n",
              "      <td>0.954689</td>\n",
              "      <td>0</td>\n",
              "      <td>Hero</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-efe50d4c-ebfe-44c0-9124-c0840523dac2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-efe50d4c-ebfe-44c0-9124-c0840523dac2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-efe50d4c-ebfe-44c0-9124-c0840523dac2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results.print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3AXtfeGfDPcx",
        "outputId": "51883fec-0a5a-4546-d805-4a23f9428580"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image 1/1: 64x128 1 Hero, 1 bullet\n",
            "Speed: 14.2ms pre-process, 57.1ms inference, 1.6ms NMS per image at shape (1, 3, 320, 640)\n"
          ]
        }
      ]
    }
  ]
}